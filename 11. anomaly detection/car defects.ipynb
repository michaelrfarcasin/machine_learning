{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bbdff4-4ffe-4668-a732-4d14669709bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539c1042-50b7-43f2-aff7-75b0ae7d6aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset from kagglehub.dataset_download(\"philanipro/mercedesbenz-greener-manufacturing\")\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00a0a94-ea8d-40b1-a0f5-7ee0bdbac870",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31625b63-512e-4111-a3ba-10b95dfd1489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strings_to_numbers(strings):\n",
    "    s = pd.Series(strings)\n",
    "    labels, levels = pd.factorize(s)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2d6ae2-24d4-49a4-8c95-1a1040613e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.iloc[:, [2, 3, 4, 5, 6, 7, 8, 9]].values\n",
    "for i in range(8):\n",
    "    X_train[:, i] = strings_to_numbers(X_train[:, i])\n",
    "X_train = X_train.astype(np.int64)\n",
    "y_train = df['X10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308be9b3-89d7-4dee-86c1-a59122e91ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2d49b1-84a4-4ade-ab6d-208e4cffba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = df_val.iloc[:, [1, 2, 3, 4, 5, 6, 7, 8]].values\n",
    "for i in range(8):\n",
    "    X_val[:, i] = strings_to_numbers(X_val[:, i]).astype(np.int64)\n",
    "X_val = X_val.astype(np.int64)\n",
    "y_val = df_val['X10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9de8e3-64f7-4238-a556-2e526f8bca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_gaussian(X): \n",
    "    \"\"\"\n",
    "    Calculates mean and variance of all features \n",
    "    in the dataset\n",
    "    \n",
    "    Args:\n",
    "        X (ndarray): (m, n) Data matrix\n",
    "    \n",
    "    Returns:\n",
    "        mu (ndarray): (n,) Mean of all features\n",
    "        var (ndarray): (n,) Variance of all features\n",
    "    \"\"\"\n",
    "    \n",
    "    mu = np.mean(X, axis = 0)\n",
    "    var = np.var(X, axis = 0)\n",
    "        \n",
    "    return mu, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19714b8-1700-477a-a634-5c68c55bca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_gaussian(X, mu, var):\n",
    "    \"\"\"\n",
    "    Computes the probability \n",
    "    density function of the examples X under the multivariate gaussian \n",
    "    distribution with parameters mu and var. If var is a matrix, it is\n",
    "    treated as the covariance matrix. If var is a vector, it is treated\n",
    "    as the var values of the variances in each dimension (a diagonal\n",
    "    covariance matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    k = len(mu)\n",
    "    \n",
    "    if var.ndim == 1:\n",
    "        var = np.diag(var)\n",
    "        \n",
    "    X = X - mu\n",
    "    p = (2* np.pi)**(-k/2) * np.linalg.det(var)**(-0.5) * \\\n",
    "        np.exp(-0.5 * np.sum(np.matmul(X, np.linalg.pinv(var)) * X, axis=1))\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a44733-1bd5-49ba-a2dc-fda244244ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_threshold(y_val, p_val): \n",
    "    \"\"\"\n",
    "    Finds the best threshold to use for selecting outliers \n",
    "    based on the results from a validation set (p_val) \n",
    "    and the ground truth (y_val)\n",
    "    \n",
    "    Args:\n",
    "        y_val (ndarray): Ground truth on validation set\n",
    "        p_val (ndarray): Results on validation set\n",
    "        \n",
    "    Returns:\n",
    "        epsilon (float): Threshold chosen \n",
    "        F1 (float):      F1 score by choosing epsilon as threshold\n",
    "    \"\"\" \n",
    "\n",
    "    best_epsilon = 0\n",
    "    best_F1 = 0\n",
    "    F1 = 0\n",
    "    \n",
    "    step_size = (max(p_val) - min(p_val)) / 1000\n",
    "    \n",
    "    for epsilon in np.arange(min(p_val), max(p_val), step_size):\n",
    "        predictions = [1 if p == True else 0 for p in (p_val < epsilon)]\n",
    "        cm = confusion_matrix(y_val, predictions)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        if tp + fp == 0 or tp + fn == 0:\n",
    "            continue\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        F1 = 2 * precision * recall / (precision + recall)\n",
    "        \n",
    "        if F1 > best_F1:\n",
    "            best_F1 = F1\n",
    "            best_epsilon = epsilon\n",
    "        \n",
    "    return best_epsilon, best_F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a8d792-07af-42ff-83e7-442f6c7eedd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1508dfe-f007-4c33-b68f-3653570d0ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the Gaussian parameters\n",
    "mu, var = estimate_gaussian(X_train)\n",
    "\n",
    "# Evaluate the probabilites for the training set\n",
    "p = multivariate_gaussian(X_train, mu, var)\n",
    "\n",
    "# Evaluate the probabilites for the cross validation set\n",
    "p_val = multivariate_gaussian(X_val, mu, var)\n",
    "\n",
    "# Find the best threshold\n",
    "epsilon, F1 = select_threshold(y_val, p_val)\n",
    "\n",
    "print('Best epsilon found using cross-validation: %e'% epsilon)\n",
    "print('Best F1 on Cross Validation Set:  %f'% F1)\n",
    "print('# Anomalies found: %d'% sum(p < epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5058306-3292-45d7-ac4b-96910222b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This F1 score looks quite bad, but there was never a guarantee that X10 in the dataset would be related to anomalies in the first 8 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ab39a5-5f5d-4b17-8de0-554a829cdfba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
