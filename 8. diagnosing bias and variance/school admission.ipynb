{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8414c4ae-cee4-4f54-aa9b-6b67aaf3872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In project 4 I used linear gradient descent and got an undefitted model with a cost of 0.79\n",
    "# this time I'll try to do better with a neural network and evaluating diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56105f8c-4796-4dbe-bedc-2587e9e8a2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.lines import Line2D\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859d938f-4b05-45f4-8ebc-86ae06c23ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_xy(dataframe):\n",
    "    data = dataframe.to_numpy()\n",
    "    y = data[:, 0]\n",
    "    X = data[:, 1:]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ce282c-bd56-4267-af60-9e8c5a39a84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_dataframe = pd.read_stata('binary.dta') # https://stats.oarc.ucla.edu/stata/dae/logistic-regression/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143b618c-1094-47e1-9f4d-cad14a7cb065",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f54e0ae-3a03-4278-b618-e51d0926952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = dataframe_to_xy(xy_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c121163-3b19-402e-a64c-d8d4dc8f883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba767a7-e308-464d-9772-7e08d3d2adc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 60% of the dataset as the training set. Put the remaining 40% in temporary variables: x_ and y_.\n",
    "x_train, x_, y_train, y_ = train_test_split(X, y, test_size=0.40, random_state=1)\n",
    "\n",
    "# Split the 40% subset above into two: one half for cross validation and the other for the test set\n",
    "x_cv, x_test, y_cv, y_test = train_test_split(x_, y_, test_size=0.50, random_state=1)\n",
    "\n",
    "# Delete temporary variables\n",
    "del x_, y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d838c864-bb16-47d4-a1e6-5de650b74615",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_train[0]) # note the first value is several orders larger than the others, so I should normalize\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d9a030-f9bc-42b1-9f4b-1bbc55c6d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_scatter_plot_3d(x1, x2, x3, y, x1_label='X axis', x2_label='Y axis', x3_label='Z axis', y_labels=['0', '1']):\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    colors = ['red' if label == 0 else 'blue' for label in y]\n",
    "    ax.scatter(x1, x2, x3, c=colors, s=50, alpha=0.8)\n",
    "    ax.set_xlabel(x1_label)\n",
    "    ax.set_ylabel(x2_label)\n",
    "    ax.set_zlabel(x3_label)\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], marker='o', color='w', label=y_labels[0], markerfacecolor='red', markersize=8),\n",
    "        Line2D([0], [0], marker='o', color='w', label=y_labels[1], markerfacecolor='blue', markersize=8)\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253d8e9d-b5fd-47c4-89ab-46ecf038eb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_scatter_plot_3d(X[:, 0], X[:, 1], X[:, 2], y, 'GRE', 'GPA', 'Rank', ['Not Admitted', 'Admitted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003b511b-8dc8-4e01-800c-185892018674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler_linear = StandardScaler()\n",
    "x_train_scaled = scaler_linear.fit_transform(x_train)\n",
    "x_cv_scaled = scaler_linear.transform(x_cv)\n",
    "x_test_scaled = scaler_linear.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f72e6e-26c3-4889-a704-67a67431b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a baseline for accuracy\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "baseline_accuracy = counts.max() / counts.sum()\n",
    "print(\"Majority baseline:\", baseline_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6bfdd8-d49a-4604-81e2-02a4783389fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a few different models\n",
    "model_1 = Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(3,)),\n",
    "        Dense(3, activation = 'relu'),\n",
    "        Dense(1, activation = 'sigmoid')\n",
    "    ],\n",
    "    name='model_1'\n",
    ")\n",
    "model_2 = Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(3,)),\n",
    "        Dense(25, activation = 'relu'),\n",
    "        Dense(15, activation = 'relu'),\n",
    "        Dense(1, activation = 'sigmoid')\n",
    "    ],\n",
    "    name='model_2'\n",
    ")\n",
    "model_3 = Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(3,)),\n",
    "        Dense(50, activation = 'relu'),\n",
    "        Dense(25, activation = 'relu'),\n",
    "        Dense(15, activation = 'relu'),\n",
    "        Dense(1, activation = 'sigmoid')\n",
    "    ],\n",
    "    name='model_3'\n",
    ")\n",
    "model_4 = Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(3,)),\n",
    "        Dense(35, activation = 'relu'),\n",
    "        Dense(25, activation = 'relu'),\n",
    "        Dense(15, activation = 'relu'),\n",
    "        Dense(5, activation = 'relu'),\n",
    "        Dense(1, activation = 'sigmoid')\n",
    "    ],\n",
    "    name='model_4'\n",
    ")\n",
    "models = [model_1, model_2, model_3, model_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa81df6-1dc3-4687-8496-cbf1d8e5979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists that will contain the errors for each model\n",
    "train_accuracies = []\n",
    "cv_accuracies = []\n",
    "histories = []\n",
    "\n",
    "# Loop over each model\n",
    "for model in models:\n",
    "    # Setup the loss and optimizer\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy(name='accuracy', threshold=0.5),\n",
    "            tf.keras.metrics.AUC(name='auc')\n",
    "        ]\n",
    "    )\n",
    "    print(f\"Training {model.name}...\")\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        x_train_scaled, \n",
    "        y_train,\n",
    "        validation_data=(x_cv_scaled, y_cv),\n",
    "        epochs=200,\n",
    "        verbose=0\n",
    "    )\n",
    "    histories.append(history)\n",
    "    print(\"Done!\")\n",
    "\n",
    "    train_results = model.evaluate(x_train_scaled, y_train, verbose=0, return_dict=True)\n",
    "    train_accuracies.append(train_results['accuracy'])\n",
    "    \n",
    "    cv_results = model.evaluate(x_cv_scaled, y_cv, verbose=0, return_dict=True)\n",
    "    cv_accuracies.append(cv_results['accuracy'])\n",
    "    print(model.name, cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e076553e-fa39-4c7e-816d-9efc0c597f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "histories[0].history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82ffefb-b392-4076-bcab-21dc3d5a6708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    # Plot loss\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(history.history['loss'], label='Training loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "    plt.title('Loss over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('BinaryCrossentropy Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(history.history['accuracy'], label='Training accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation accuracy')\n",
    "    plt.axhline(y=baseline_accuracy, color='r', linestyle=':', label='Baseline accuracy')\n",
    "    plt.title('Accuracy over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4893e97d-ed16-4480-84e4-a3e5ac67f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(histories)):\n",
    "    history = histories[i]\n",
    "    print(f'Model {i+1}')\n",
    "    plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ebcaa-b05b-46bc-9bd2-bc331aef9835",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = np.argmax(cv_accuracies)\n",
    "model = models[model_num]\n",
    "print(f'{model.name} has the best accuracy: {cv_accuracies[model_num]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fec0c9-2a20-4dcc-bf9b-778f01c9a28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4 has the best accuracy, but its loss graph shows validation loss rising and training loss falling - indicating overfitting\n",
    "# we could reduce the number of features, or add regularization \n",
    "# since the other models already have fewer features and worse accuracy aside from model 1, let's try adding regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9253b5-8528-4b57-9f33-d7aa8c28be47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists that will contain the errors for each model\n",
    "reg_train_accuracies = []\n",
    "reg_cv_accuracies = []\n",
    "reg_histories = []\n",
    "reg_params = [1, 0.5, 0.2, 0.1, 0.05, 0.02, 0.01, 0.005, 0.002, 0.001]\n",
    "reg_models = []\n",
    "\n",
    "# Loop over each model\n",
    "for lambda_ in reg_params:\n",
    "    # Build the model\n",
    "    model = Sequential(\n",
    "        [\n",
    "            tf.keras.Input(shape=(3,)),\n",
    "            Dense(35, activation = 'relu', kernel_regularizer=l2(lambda_)),\n",
    "            Dense(25, activation = 'relu', kernel_regularizer=l2(lambda_)),\n",
    "            Dense(15, activation = 'relu', kernel_regularizer=l2(lambda_)),\n",
    "            Dense(5, activation = 'relu', kernel_regularizer=l2(lambda_)),\n",
    "            Dense(1, activation = 'sigmoid')\n",
    "        ],\n",
    "        name='model_4'\n",
    "    )\n",
    "    reg_models.append(model)\n",
    "    \n",
    "    # Setup the loss and optimizer\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy(name='accuracy', threshold=0.5),\n",
    "            tf.keras.metrics.AUC(name='auc')\n",
    "        ]\n",
    "    )\n",
    "    print(f\"Training {model.name} with lambda {lambda_}...\")\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        x_train_scaled, \n",
    "        y_train,\n",
    "        validation_data=(x_cv_scaled, y_cv),\n",
    "        epochs=100,\n",
    "        verbose=0\n",
    "    )\n",
    "    reg_histories.append(history)\n",
    "    print(\"Done!\")\n",
    "\n",
    "    train_results = model.evaluate(x_train_scaled, y_train, verbose=0, return_dict=True)\n",
    "    reg_train_accuracies.append(train_results['accuracy'])\n",
    "    \n",
    "    cv_results = model.evaluate(x_cv_scaled, y_cv, verbose=0, return_dict=True)\n",
    "    reg_cv_accuracies.append(cv_results['accuracy'])\n",
    "    print(lambda_, cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c16166-b806-4b39-ad53-55883102cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_num = np.argmax(reg_cv_accuracies)\n",
    "model = reg_models[reg_num]\n",
    "print(f'{model.name} with lambda {reg_params[reg_num]} has the best accuracy: {cv_accuracies[model_num]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbd9e2e-29bd-414c-81ad-0df09fd936ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(reg_histories)):\n",
    "    history = reg_histories[i]\n",
    "    print(f'Model {i+1} with lambda {reg_params[i]}')\n",
    "    plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331ce990-00b0-414d-b1d4-a0c3deefd827",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = model.evaluate(x_test_scaled, y_test, verbose=0, return_dict=True)\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd99ed53-f0f0-4901-a1ff-c68633c94cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(x_test_scaled)\n",
    "fx = [0 if p < 0.5 else 1 for p in prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c938f0-c539-4ec2-a27a-287f59dd2581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_scatter_plot_3d_with_fx(x1, x2, x3, y, fx, x1_label='X axis', x2_label='Y axis', x3_label='Z axis'):\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    colors_actual = ['red' if label == 0 else 'blue' for label in y]\n",
    "    ax.scatter(x1, x2, x3, c=colors_actual, s=50, alpha=0.4, label='Actual')\n",
    "    colors_predicted = ['pink' if label == 0 else 'lightblue' for label in fx]\n",
    "    ax.scatter(x1, x2, x3, c=colors_predicted, s=20, alpha=0.8, label='Predicted', marker='^')\n",
    "    ax.set_xlabel(x1_label)\n",
    "    ax.set_ylabel(x2_label)\n",
    "    ax.set_zlabel(x3_label)\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], marker='o', color='w', label='Actual 0', markerfacecolor='red', markersize=8),\n",
    "        Line2D([0], [0], marker='o', color='w', label='Actual 1', markerfacecolor='blue', markersize=8),\n",
    "        Line2D([0], [0], marker='^', color='w', label='Predicted 0', markerfacecolor='pink', markersize=8),\n",
    "        Line2D([0], [0], marker='^', color='w', label='Predicted 1', markerfacecolor='lightblue', markersize=8)\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10d040d-3900-4942-883c-b040704f7baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_scatter_plot_3d_with_fx(x_test[:, 0], x_test[:, 1], x_test[:, 2], y_test, fx, 'GRE', 'GPA', 'Rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042e8216-f571-4f0b-9c26-a08d2e110c7c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy_improvement = test_results['accuracy'] - baseline_accuracy\n",
    "print(f'{test_results['accuracy']:.3f} is a {accuracy_improvement:.3f} improvement over the baseline {baseline_accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff9fc89-50d8-4486-98b6-d772d30132cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.725 is markedly better than the 0.21 accuracy I got in project 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8a684f-777f-4c2c-8939-2b1f28437d16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
